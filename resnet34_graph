digraph {
	graph [size="106.35,106.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1883296601392 [label="
 (1, 500)" fillcolor=darkolivegreen1]
	1882604222928 [label=AddmmBackward0]
	1882604215632 -> 1882604222928
	1883282538016 [label="network.fc.bias
 (500)" fillcolor=lightblue]
	1883282538016 -> 1882604215632
	1882604215632 [label=AccumulateGrad]
	1882604215344 -> 1882604222928
	1882604215344 [label=ReshapeAliasBackward0]
	1882604218560 -> 1882604215344
	1882604218560 [label=MeanBackward1]
	1882604221056 -> 1882604218560
	1882604221056 [label=ReluBackward0]
	1882604224176 -> 1882604221056
	1882604224176 [label=AddBackward0]
	1882604217792 -> 1882604224176
	1882604217792 [label=NativeBatchNormBackward0]
	1882604222976 -> 1882604217792
	1882604222976 [label=ConvolutionBackward0]
	1882604220960 -> 1882604222976
	1882604220960 [label=ReluBackward0]
	1883289380960 -> 1882604220960
	1883289380960 [label=NativeBatchNormBackward0]
	1883289380288 -> 1883289380960
	1883289380288 [label=ConvolutionBackward0]
	1882604215824 -> 1883289380288
	1882604215824 [label=ReluBackward0]
	1883289381008 -> 1882604215824
	1883289381008 [label=AddBackward0]
	1883289382496 -> 1883289381008
	1883289382496 [label=NativeBatchNormBackward0]
	1883289382640 -> 1883289382496
	1883289382640 [label=ConvolutionBackward0]
	1883289386096 -> 1883289382640
	1883289386096 [label=ReluBackward0]
	1883289386240 -> 1883289386096
	1883289386240 [label=NativeBatchNormBackward0]
	1883289386336 -> 1883289386240
	1883289386336 [label=ConvolutionBackward0]
	1883289386000 -> 1883289386336
	1883289386000 [label=ReluBackward0]
	1883289380336 -> 1883289386000
	1883289380336 [label=AddBackward0]
	1883289380384 -> 1883289380336
	1883289380384 [label=NativeBatchNormBackward0]
	1883296237552 -> 1883289380384
	1883296237552 [label=ConvolutionBackward0]
	1883296237648 -> 1883296237552
	1883296237648 [label=ReluBackward0]
	1883296237504 -> 1883296237648
	1883296237504 [label=NativeBatchNormBackward0]
	1883296237408 -> 1883296237504
	1883296237408 [label=ConvolutionBackward0]
	1883296236928 -> 1883296237408
	1883296236928 [label=ReluBackward0]
	1883296237216 -> 1883296236928
	1883296237216 [label=AddBackward0]
	1883296237120 -> 1883296237216
	1883296237120 [label=NativeBatchNormBackward0]
	1883296236784 -> 1883296237120
	1883296236784 [label=ConvolutionBackward0]
	1883296236640 -> 1883296236784
	1883296236640 [label=ReluBackward0]
	1883296236208 -> 1883296236640
	1883296236208 [label=NativeBatchNormBackward0]
	1883296236400 -> 1883296236208
	1883296236400 [label=ConvolutionBackward0]
	1883296237168 -> 1883296236400
	1883296237168 [label=ReluBackward0]
	1883296236112 -> 1883296237168
	1883296236112 [label=AddBackward0]
	1883296236016 -> 1883296236112
	1883296236016 [label=NativeBatchNormBackward0]
	1883296235872 -> 1883296236016
	1883296235872 [label=ConvolutionBackward0]
	1883296235680 -> 1883296235872
	1883296235680 [label=ReluBackward0]
	1883296237984 -> 1883296235680
	1883296237984 [label=NativeBatchNormBackward0]
	1883296238272 -> 1883296237984
	1883296238272 [label=ConvolutionBackward0]
	1883296236064 -> 1883296238272
	1883296236064 [label=ReluBackward0]
	1883296238848 -> 1883296236064
	1883296238848 [label=AddBackward0]
	1883296238464 -> 1883296238848
	1883296238464 [label=NativeBatchNormBackward0]
	1883296240048 -> 1883296238464
	1883296240048 [label=ConvolutionBackward0]
	1883296241200 -> 1883296240048
	1883296241200 [label=ReluBackward0]
	1883296241920 -> 1883296241200
	1883296241920 [label=NativeBatchNormBackward0]
	1883296242016 -> 1883296241920
	1883296242016 [label=ConvolutionBackward0]
	1883296239952 -> 1883296242016
	1883296239952 [label=ReluBackward0]
	1883296242736 -> 1883296239952
	1883296242736 [label=AddBackward0]
	1883296243792 -> 1883296242736
	1883296243792 [label=NativeBatchNormBackward0]
	1883296244272 -> 1883296243792
	1883296244272 [label=ConvolutionBackward0]
	1883296245472 -> 1883296244272
	1883296245472 [label=ReluBackward0]
	1883296247728 -> 1883296245472
	1883296247728 [label=NativeBatchNormBackward0]
	1883296248304 -> 1883296247728
	1883296248304 [label=ConvolutionBackward0]
	1883296242688 -> 1883296248304
	1883296242688 [label=ReluBackward0]
	1883296250272 -> 1883296242688
	1883296250272 [label=AddBackward0]
	1883296250464 -> 1883296250272
	1883296250464 [label=NativeBatchNormBackward0]
	1883296250512 -> 1883296250464
	1883296250512 [label=ConvolutionBackward0]
	1883296250752 -> 1883296250512
	1883296250752 [label=ReluBackward0]
	1883296251184 -> 1883296250752
	1883296251184 [label=NativeBatchNormBackward0]
	1883296251328 -> 1883296251184
	1883296251328 [label=ConvolutionBackward0]
	1883296250224 -> 1883296251328
	1883296250224 [label=ReluBackward0]
	1883296251616 -> 1883296250224
	1883296251616 [label=AddBackward0]
	1883296251760 -> 1883296251616
	1883296251760 [label=NativeBatchNormBackward0]
	1883296251808 -> 1883296251760
	1883296251808 [label=ConvolutionBackward0]
	1883296479312 -> 1883296251808
	1883296479312 [label=ReluBackward0]
	1883296465824 -> 1883296479312
	1883296465824 [label=NativeBatchNormBackward0]
	1883296478640 -> 1883296465824
	1883296478640 [label=ConvolutionBackward0]
	1883296480656 -> 1883296478640
	1883296480656 [label=ReluBackward0]
	1883296465008 -> 1883296480656
	1883296465008 [label=AddBackward0]
	1883296465104 -> 1883296465008
	1883296465104 [label=NativeBatchNormBackward0]
	1883296465296 -> 1883296465104
	1883296465296 [label=ConvolutionBackward0]
	1883296465968 -> 1883296465296
	1883296465968 [label=ReluBackward0]
	1883296466352 -> 1883296465968
	1883296466352 [label=NativeBatchNormBackward0]
	1883296466736 -> 1883296466352
	1883296466736 [label=ConvolutionBackward0]
	1883296465056 -> 1883296466736
	1883296465056 [label=ReluBackward0]
	1883296467360 -> 1883296465056
	1883296467360 [label=AddBackward0]
	1883296467696 -> 1883296467360
	1883296467696 [label=NativeBatchNormBackward0]
	1883296468080 -> 1883296467696
	1883296468080 [label=ConvolutionBackward0]
	1883296468560 -> 1883296468080
	1883296468560 [label=ReluBackward0]
	1883296468896 -> 1883296468560
	1883296468896 [label=NativeBatchNormBackward0]
	1883296469376 -> 1883296468896
	1883296469376 [label=ConvolutionBackward0]
	1883296467648 -> 1883296469376
	1883296467648 [label=ReluBackward0]
	1883296470192 -> 1883296467648
	1883296470192 [label=AddBackward0]
	1883296470288 -> 1883296470192
	1883296470288 [label=NativeBatchNormBackward0]
	1883296470624 -> 1883296470288
	1883296470624 [label=ConvolutionBackward0]
	1883296471296 -> 1883296470624
	1883296471296 [label=ReluBackward0]
	1883296471680 -> 1883296471296
	1883296471680 [label=NativeBatchNormBackward0]
	1883296471968 -> 1883296471680
	1883296471968 [label=ConvolutionBackward0]
	1883296470240 -> 1883296471968
	1883296470240 [label=ReluBackward0]
	1883296472832 -> 1883296470240
	1883296472832 [label=AddBackward0]
	1883296473024 -> 1883296472832
	1883296473024 [label=NativeBatchNormBackward0]
	1883296473408 -> 1883296473024
	1883296473408 [label=ConvolutionBackward0]
	1883296473888 -> 1883296473408
	1883296473888 [label=ReluBackward0]
	1883296474272 -> 1883296473888
	1883296474272 [label=NativeBatchNormBackward0]
	1883296474464 -> 1883296474272
	1883296474464 [label=ConvolutionBackward0]
	1883296474800 -> 1883296474464
	1883296474800 [label=ReluBackward0]
	1883296475184 -> 1883296474800
	1883296475184 [label=AddBackward0]
	1883296475376 -> 1883296475184
	1883296475376 [label=NativeBatchNormBackward0]
	1883296475616 -> 1883296475376
	1883296475616 [label=ConvolutionBackward0]
	1883296476048 -> 1883296475616
	1883296476048 [label=ReluBackward0]
	1883296476528 -> 1883296476048
	1883296476528 [label=NativeBatchNormBackward0]
	1883296476864 -> 1883296476528
	1883296476864 [label=ConvolutionBackward0]
	1883296475328 -> 1883296476864
	1883296475328 [label=ReluBackward0]
	1883296477536 -> 1883296475328
	1883296477536 [label=AddBackward0]
	1883296477776 -> 1883296477536
	1883296477776 [label=NativeBatchNormBackward0]
	1883296478256 -> 1883296477776
	1883296478256 [label=ConvolutionBackward0]
	1883296593088 -> 1883296478256
	1883296593088 [label=ReluBackward0]
	1883296592848 -> 1883296593088
	1883296592848 [label=NativeBatchNormBackward0]
	1883296592656 -> 1883296592848
	1883296592656 [label=ConvolutionBackward0]
	1883296477584 -> 1883296592656
	1883296477584 [label=ReluBackward0]
	1883296592320 -> 1883296477584
	1883296592320 [label=AddBackward0]
	1883296592224 -> 1883296592320
	1883296592224 [label=NativeBatchNormBackward0]
	1883296591984 -> 1883296592224
	1883296591984 [label=ConvolutionBackward0]
	1883296591792 -> 1883296591984
	1883296591792 [label=ReluBackward0]
	1883296591744 -> 1883296591792
	1883296591744 [label=NativeBatchNormBackward0]
	1883296591648 -> 1883296591744
	1883296591648 [label=ConvolutionBackward0]
	1883296592176 -> 1883296591648
	1883296592176 [label=MaxPool2DWithIndicesBackward0]
	1883296590400 -> 1883296592176
	1883296590400 [label=ReluBackward0]
	1883296584208 -> 1883296590400
	1883296584208 [label=NativeBatchNormBackward0]
	1883296584736 -> 1883296584208
	1883296584736 [label=ConvolutionBackward0]
	1883296585792 -> 1883296584736
	1883296481584 [label="network.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	1883296481584 -> 1883296585792
	1883296585792 [label=AccumulateGrad]
	1883296584352 -> 1883296584208
	1883296483744 [label="network.bn1.weight
 (64)" fillcolor=lightblue]
	1883296483744 -> 1883296584352
	1883296584352 [label=AccumulateGrad]
	1883296591552 -> 1883296584208
	1883281621936 [label="network.bn1.bias
 (64)" fillcolor=lightblue]
	1883281621936 -> 1883296591552
	1883296591552 [label=AccumulateGrad]
	1883296591456 -> 1883296591648
	1883296416608 [label="network.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1883296416608 -> 1883296591456
	1883296591456 [label=AccumulateGrad]
	1883296591600 -> 1883296591744
	1883296421968 [label="network.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1883296421968 -> 1883296591600
	1883296591600 [label=AccumulateGrad]
	1883296591840 -> 1883296591744
	1883296418848 [label="network.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1883296418848 -> 1883296591840
	1883296591840 [label=AccumulateGrad]
	1883296591936 -> 1883296591984
	1883296416208 [label="network.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1883296416208 -> 1883296591936
	1883296591936 [label=AccumulateGrad]
	1883296592128 -> 1883296592224
	1883296427488 [label="network.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1883296427488 -> 1883296592128
	1883296592128 [label=AccumulateGrad]
	1883296592080 -> 1883296592224
	1883296416048 [label="network.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1883296416048 -> 1883296592080
	1883296592080 [label=AccumulateGrad]
	1883296592176 -> 1883296592320
	1883296592416 -> 1883296592656
	1883296420048 [label="network.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1883296420048 -> 1883296592416
	1883296592416 [label=AccumulateGrad]
	1883296592704 -> 1883296592848
	1883296419648 [label="network.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1883296419648 -> 1883296592704
	1883296592704 [label=AccumulateGrad]
	1883296592992 -> 1883296592848
	1883296421248 [label="network.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1883296421248 -> 1883296592992
	1883296592992 [label=AccumulateGrad]
	1883296593040 -> 1883296478256
	1883296425648 [label="network.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1883296425648 -> 1883296593040
	1883296593040 [label=AccumulateGrad]
	1883296479072 -> 1883296477776
	1883296425248 [label="network.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1883296425248 -> 1883296479072
	1883296479072 [label=AccumulateGrad]
	1883296478448 -> 1883296477776
	1883296426048 [label="network.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1883296426048 -> 1883296478448
	1883296478448 [label=AccumulateGrad]
	1883296477584 -> 1883296477536
	1883296477344 -> 1883296476864
	1883296431568 [label="network.layer1.2.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1883296431568 -> 1883296477344
	1883296477344 [label=AccumulateGrad]
	1883296476720 -> 1883296476528
	1883296430848 [label="network.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	1883296430848 -> 1883296476720
	1883296476720 [label=AccumulateGrad]
	1883296476336 -> 1883296476528
	1883296417168 [label="network.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	1883296417168 -> 1883296476336
	1883296476336 [label=AccumulateGrad]
	1883296475856 -> 1883296475616
	1883296419968 [label="network.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1883296419968 -> 1883296475856
	1883296475856 [label=AccumulateGrad]
	1883296475472 -> 1883296475376
	1883296416448 [label="network.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	1883296416448 -> 1883296475472
	1883296475472 [label=AccumulateGrad]
	1883296475424 -> 1883296475376
	1883289180480 [label="network.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	1883289180480 -> 1883296475424
	1883296475424 [label=AccumulateGrad]
	1883296475328 -> 1883296475184
	1883296474752 -> 1883296474464
	1883296222480 [label="network.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1883296222480 -> 1883296474752
	1883296474752 [label=AccumulateGrad]
	1883296474320 -> 1883296474272
	1883296221280 [label="network.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1883296221280 -> 1883296474320
	1883296474320 [label=AccumulateGrad]
	1883296473936 -> 1883296474272
	1883296229040 [label="network.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1883296229040 -> 1883296473936
	1883296473936 [label=AccumulateGrad]
	1883296473744 -> 1883296473408
	1883296235280 [label="network.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1883296235280 -> 1883296473744
	1883296473744 [label=AccumulateGrad]
	1883296473264 -> 1883296473024
	1883296235360 [label="network.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1883296235360 -> 1883296473264
	1883296473264 [label=AccumulateGrad]
	1883296473216 -> 1883296473024
	1883296234960 [label="network.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1883296234960 -> 1883296473216
	1883296473216 [label=AccumulateGrad]
	1883296472880 -> 1883296472832
	1883296472880 [label=NativeBatchNormBackward0]
	1883296474608 -> 1883296472880
	1883296474608 [label=ConvolutionBackward0]
	1883296474800 -> 1883296474608
	1883296474992 -> 1883296474608
	1882925501712 [label="network.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1882925501712 -> 1883296474992
	1883296474992 [label=AccumulateGrad]
	1883296473696 -> 1883296472880
	1883282537616 [label="network.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	1883282537616 -> 1883296473696
	1883296473696 [label=AccumulateGrad]
	1883296473648 -> 1883296472880
	1883282528096 [label="network.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	1883282528096 -> 1883296473648
	1883296473648 [label=AccumulateGrad]
	1883296472352 -> 1883296471968
	1883296234640 [label="network.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1883296234640 -> 1883296472352
	1883296472352 [label=AccumulateGrad]
	1883296471920 -> 1883296471680
	1883296229920 [label="network.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1883296229920 -> 1883296471920
	1883296471920 [label=AccumulateGrad]
	1883296471488 -> 1883296471680
	1883296234240 [label="network.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1883296234240 -> 1883296471488
	1883296471488 [label=AccumulateGrad]
	1883296471152 -> 1883296470624
	1883296232960 [label="network.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1883296232960 -> 1883296471152
	1883296471152 [label=AccumulateGrad]
	1883296470480 -> 1883296470288
	1883296233040 [label="network.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1883296233040 -> 1883296470480
	1883296470480 [label=AccumulateGrad]
	1883296470432 -> 1883296470288
	1883296232720 [label="network.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1883296232720 -> 1883296470432
	1883296470432 [label=AccumulateGrad]
	1883296470240 -> 1883296470192
	1883296469808 -> 1883296469376
	1883296231120 [label="network.layer2.2.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1883296231120 -> 1883296469808
	1883296469808 [label=AccumulateGrad]
	1883296469088 -> 1883296468896
	1883296231440 [label="network.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	1883296231440 -> 1883296469088
	1883296469088 [label=AccumulateGrad]
	1883296468704 -> 1883296468896
	1883296230880 [label="network.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	1883296230880 -> 1883296468704
	1883296468704 [label=AccumulateGrad]
	1883296468512 -> 1883296468080
	1883296232080 [label="network.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1883296232080 -> 1883296468512
	1883296468512 [label=AccumulateGrad]
	1883296468032 -> 1883296467696
	1883296231680 [label="network.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	1883296231680 -> 1883296468032
	1883296468032 [label=AccumulateGrad]
	1883296467840 -> 1883296467696
	1883296233280 [label="network.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	1883296233280 -> 1883296467840
	1883296467840 [label=AccumulateGrad]
	1883296467648 -> 1883296467360
	1883296467024 -> 1883296466736
	1883296230720 [label="network.layer2.3.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1883296230720 -> 1883296467024
	1883296467024 [label=AccumulateGrad]
	1883296466496 -> 1883296466352
	1883296230240 [label="network.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	1883296230240 -> 1883296466496
	1883296466496 [label=AccumulateGrad]
	1883296466112 -> 1883296466352
	1883296230320 [label="network.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	1883296230320 -> 1883296466112
	1883296466112 [label=AccumulateGrad]
	1883296465920 -> 1883296465296
	1883289446144 [label="network.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1883289446144 -> 1883296465920
	1883296465920 [label=AccumulateGrad]
	1883296465248 -> 1883296465104
	1883289449744 [label="network.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	1883289449744 -> 1883296465248
	1883296465248 [label=AccumulateGrad]
	1883296465152 -> 1883296465104
	1883289451264 [label="network.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	1883289451264 -> 1883296465152
	1883296465152 [label=AccumulateGrad]
	1883296465056 -> 1883296465008
	1883296476912 -> 1883296478640
	1883296559120 [label="network.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1883296559120 -> 1883296476912
	1883296476912 [label=AccumulateGrad]
	1883296479264 -> 1883296465824
	1883296547520 [label="network.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1883296547520 -> 1883296479264
	1883296479264 [label=AccumulateGrad]
	1883296479504 -> 1883296465824
	1883296560080 [label="network.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1883296560080 -> 1883296479504
	1883296479504 [label=AccumulateGrad]
	1883296479744 -> 1883296251808
	1883296562720 [label="network.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296562720 -> 1883296479744
	1883296479744 [label=AccumulateGrad]
	1883296251664 -> 1883296251760
	1883296563040 [label="network.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1883296563040 -> 1883296251664
	1883296251664 [label=AccumulateGrad]
	1883296467888 -> 1883296251760
	1883296562640 [label="network.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1883296562640 -> 1883296467888
	1883296467888 [label=AccumulateGrad]
	1883296251568 -> 1883296251616
	1883296251568 [label=NativeBatchNormBackward0]
	1883296478928 -> 1883296251568
	1883296478928 [label=ConvolutionBackward0]
	1883296480656 -> 1883296478928
	1883296480368 -> 1883296478928
	1883289447664 [label="network.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1883289447664 -> 1883296480368
	1883296480368 [label=AccumulateGrad]
	1883296467216 -> 1883296251568
	1883289444464 [label="network.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1883289444464 -> 1883296467216
	1883296467216 [label=AccumulateGrad]
	1883296466544 -> 1883296251568
	1883296555680 [label="network.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1883296555680 -> 1883296466544
	1883296466544 [label=AccumulateGrad]
	1883296251520 -> 1883296251328
	1883296561440 [label="network.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296561440 -> 1883296251520
	1883296251520 [label=AccumulateGrad]
	1883296251136 -> 1883296251184
	1883296561520 [label="network.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1883296561520 -> 1883296251136
	1883296251136 [label=AccumulateGrad]
	1883296251040 -> 1883296251184
	1883296561200 [label="network.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1883296561200 -> 1883296251040
	1883296251040 [label=AccumulateGrad]
	1883296250944 -> 1883296250512
	1883296559840 [label="network.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296559840 -> 1883296250944
	1883296250944 [label=AccumulateGrad]
	1883296250560 -> 1883296250464
	1883296559920 [label="network.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1883296559920 -> 1883296250560
	1883296250560 [label=AccumulateGrad]
	1883296250416 -> 1883296250464
	1883296559600 [label="network.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1883296559600 -> 1883296250416
	1883296250416 [label=AccumulateGrad]
	1883296250224 -> 1883296250272
	1883296250176 -> 1883296248304
	1883296558160 [label="network.layer3.2.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296558160 -> 1883296250176
	1883296250176 [label=AccumulateGrad]
	1883296247200 -> 1883296247728
	1883296558480 [label="network.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	1883296558480 -> 1883296247200
	1883296247200 [label=AccumulateGrad]
	1883296247104 -> 1883296247728
	1883296558080 [label="network.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	1883296558080 -> 1883296247104
	1883296247104 [label=AccumulateGrad]
	1883296246480 -> 1883296244272
	1883296557040 [label="network.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296557040 -> 1883296246480
	1883296246480 [label=AccumulateGrad]
	1883296244368 -> 1883296243792
	1883296557120 [label="network.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	1883296557120 -> 1883296244368
	1883296244368 [label=AccumulateGrad]
	1883296242928 -> 1883296243792
	1883296556640 [label="network.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	1883296556640 -> 1883296242928
	1883296242928 [label=AccumulateGrad]
	1883296242688 -> 1883296242736
	1883296242592 -> 1883296242016
	1883296555440 [label="network.layer3.3.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296555440 -> 1883296242592
	1883296242592 [label=AccumulateGrad]
	1883296241872 -> 1883296241920
	1883296555520 [label="network.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	1883296555520 -> 1883296241872
	1883296241872 [label=AccumulateGrad]
	1883296241728 -> 1883296241920
	1883296555120 [label="network.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	1883296555120 -> 1883296241728
	1883296241728 [label=AccumulateGrad]
	1883296241344 -> 1883296240048
	1883296553920 [label="network.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296553920 -> 1883296241344
	1883296241344 [label=AccumulateGrad]
	1883296239232 -> 1883296238464
	1883296554240 [label="network.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	1883296554240 -> 1883296239232
	1883296239232 [label=AccumulateGrad]
	1883296240576 -> 1883296238464
	1883296553840 [label="network.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	1883296553840 -> 1883296240576
	1883296240576 [label=AccumulateGrad]
	1883296239952 -> 1883296238848
	1883296238944 -> 1883296238272
	1883296552400 [label="network.layer3.4.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296552400 -> 1883296238944
	1883296238944 [label=AccumulateGrad]
	1883296238032 -> 1883296237984
	1883296552720 [label="network.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	1883296552720 -> 1883296238032
	1883296238032 [label=AccumulateGrad]
	1883296235584 -> 1883296237984
	1883296552320 [label="network.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	1883296552320 -> 1883296235584
	1883296235584 [label=AccumulateGrad]
	1883296235728 -> 1883296235872
	1883296550880 [label="network.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296550880 -> 1883296235728
	1883296235728 [label=AccumulateGrad]
	1883296235632 -> 1883296236016
	1883296551200 [label="network.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	1883296551200 -> 1883296235632
	1883296235632 [label=AccumulateGrad]
	1883296235968 -> 1883296236016
	1883296550800 [label="network.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	1883296550800 -> 1883296235968
	1883296235968 [label=AccumulateGrad]
	1883296236064 -> 1883296236112
	1883296235920 -> 1883296236400
	1883296549520 [label="network.layer3.5.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296549520 -> 1883296235920
	1883296235920 [label=AccumulateGrad]
	1883296236448 -> 1883296236208
	1883296549680 [label="network.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	1883296549680 -> 1883296236448
	1883296236448 [label=AccumulateGrad]
	1883296236592 -> 1883296236208
	1883296549440 [label="network.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	1883296549440 -> 1883296236592
	1883296236592 [label=AccumulateGrad]
	1883296236688 -> 1883296236784
	1883296547760 [label="network.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1883296547760 -> 1883296236688
	1883296236688 [label=AccumulateGrad]
	1883296237024 -> 1883296237120
	1883296548080 [label="network.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	1883296548080 -> 1883296237024
	1883296237024 [label=AccumulateGrad]
	1883296237072 -> 1883296237120
	1883296547680 [label="network.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	1883296547680 -> 1883296237072
	1883296237072 [label=AccumulateGrad]
	1883296237168 -> 1883296237216
	1883296236976 -> 1883296237408
	1883296550720 [label="network.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1883296550720 -> 1883296236976
	1883296236976 [label=AccumulateGrad]
	1883296237456 -> 1883296237504
	1883296550400 [label="network.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1883296550400 -> 1883296237456
	1883296237456 [label=AccumulateGrad]
	1883296237600 -> 1883296237504
	1883296552240 [label="network.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1883296552240 -> 1883296237600
	1883296237600 [label=AccumulateGrad]
	1883296237696 -> 1883296237552
	1883296556880 [label="network.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1883296556880 -> 1883296237696
	1883296237696 [label=AccumulateGrad]
	1883296237888 -> 1883289380384
	1883296556480 [label="network.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1883296556480 -> 1883296237888
	1883296237888 [label=AccumulateGrad]
	1883296237936 -> 1883289380384
	1883296558400 [label="network.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1883296558400 -> 1883296237936
	1883296237936 [label=AccumulateGrad]
	1883289381056 -> 1883289380336
	1883289381056 [label=NativeBatchNormBackward0]
	1883296237312 -> 1883289381056
	1883296237312 [label=ConvolutionBackward0]
	1883296236928 -> 1883296237312
	1883296236880 -> 1883296237312
	1883296550320 [label="network.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1883296550320 -> 1883296236880
	1883296236880 [label=AccumulateGrad]
	1883296237840 -> 1883289381056
	1883296562400 [label="network.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1883296562400 -> 1883296237840
	1883296237840 [label=AccumulateGrad]
	1883296237744 -> 1883289381056
	1883296551440 [label="network.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1883296551440 -> 1883296237744
	1883296237744 [label=AccumulateGrad]
	1883289380768 -> 1883289386336
	1883296598112 [label="network.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1883296598112 -> 1883289380768
	1883289380768 [label=AccumulateGrad]
	1883289380576 -> 1883289386240
	1883296417328 [label="network.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1883296417328 -> 1883289380576
	1883289380576 [label=AccumulateGrad]
	1883289386144 -> 1883289386240
	1883296417408 [label="network.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1883296417408 -> 1883289386144
	1883289386144 [label=AccumulateGrad]
	1883289386048 -> 1883289382640
	1883296418928 [label="network.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1883296418928 -> 1883289386048
	1883289386048 [label=AccumulateGrad]
	1883289382592 -> 1883289382496
	1883296418688 [label="network.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1883296418688 -> 1883289382592
	1883289382592 [label=AccumulateGrad]
	1883289382544 -> 1883289382496
	1883296419328 [label="network.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1883296419328 -> 1883289382544
	1883289382544 [label=AccumulateGrad]
	1883289386000 -> 1883289381008
	1883289381920 -> 1883289380288
	1883296420608 [label="network.layer4.2.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1883296420608 -> 1883289381920
	1883289381920 [label=AccumulateGrad]
	1883289381584 -> 1883289380960
	1883296420288 [label="network.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	1883296420288 -> 1883289381584
	1883289381584 [label=AccumulateGrad]
	1883289381680 -> 1883289380960
	1883296420688 [label="network.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	1883296420688 -> 1883289381680
	1883289381680 [label=AccumulateGrad]
	1882604215872 -> 1882604222976
	1883296422208 [label="network.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1883296422208 -> 1882604215872
	1882604215872 [label=AccumulateGrad]
	1882604215392 -> 1882604217792
	1883296421808 [label="network.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	1883296421808 -> 1882604215392
	1882604215392 [label=AccumulateGrad]
	1882604220816 -> 1882604217792
	1883296422288 [label="network.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	1883296422288 -> 1882604220816
	1882604220816 [label=AccumulateGrad]
	1882604215824 -> 1882604224176
	1882604215296 -> 1882604222928
	1882604215296 [label=TBackward0]
	1882604218800 -> 1882604215296
	1883282801824 [label="network.fc.weight
 (500, 512)" fillcolor=lightblue]
	1883282801824 -> 1882604218800
	1882604218800 [label=AccumulateGrad]
	1882604222928 -> 1883296601392
}
