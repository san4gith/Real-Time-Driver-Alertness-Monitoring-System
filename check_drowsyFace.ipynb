{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Import all required libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import playsound\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Let's initialize a* **video capturing object** *to begin capturing frames from the default camera.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Now, we'll use the face classification model provided by* **Mediapipe** *, a popular library for building real-time applications using* **computer vision** *and* **machine learning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe's face classification model\n",
    "face_mesh = mp.solutions.face_mesh\n",
    "face_model = face_mesh.FaceMesh(static_image_mode = False, refine_landmarks = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Define a function named* **EAR** *to evaluate* **Eye Aspect Ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eye aspect ratio \n",
    "def EAR(eye):\n",
    "    num = dis.euclidean(eye[2], eye[3])\n",
    "    denom = dis.euclidean(eye[0], eye[1])\n",
    "    ear = num / denom\n",
    "    return ear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Define a function named* **LAR** *to evaluate* **Lip Aspect Ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lip aspect ratio\n",
    "def LAR(vert, horz):\n",
    "    num = dis.euclidean(horz[0], horz[1])\n",
    "    denom = dis.euclidean(vert[0], vert[1])\n",
    "    ear = num / denom\n",
    "    return ear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Define a function named* **sound** *that allows you to play a sound file by providing it's path (i.e., path of* **.wav** *file) as a parameter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "\n",
    "# Function to play the alarm sound while alarm is on\n",
    "def sound(path):\n",
    "  while(s):\n",
    "    playsound.playsound(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Initialization of some* **local variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count number of frames\n",
    "counter_eye = 0 \n",
    "\n",
    "# Whether to play the alarm sound or not\n",
    "alarm = 0 \n",
    "counter_lip = 0\n",
    "a = 0\n",
    "d = np.zeros(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Now, we'll perform eye and lip analysis to detect* **drowsiness** *and* **yawning** *in a video stream.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_9504\\3265192932.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  ear = num / denom\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    isTrue, frame = cap.read()\n",
    "    if isTrue == 0:\n",
    "        break \n",
    "\n",
    "    # Converting image to rgb\n",
    "    rgb_im = cv.cvtColor(frame, cv.COLOR_BGR2RGB) \n",
    "\n",
    "    # Finding landmarks for face\n",
    "    output = face_model.process(rgb_im)\n",
    "    try:\n",
    "        output = output.multi_face_landmarks[0]\n",
    "    except:\n",
    "        cv.imshow('Video', frame)\n",
    "        key = cv.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "        continue\n",
    "    \n",
    "    l = []\n",
    "    for landmark in output.landmark:\n",
    "        # Denormalizing points\n",
    "        x = (landmark.x) * frame.shape[1] \n",
    "        y = (landmark.y) * frame.shape[0]\n",
    "        l.append([x, y])\n",
    "    l = np.array(l, dtype = int)\n",
    "\n",
    "    # Indexes of landmarks of left and right eye\n",
    "    left_eye = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398]\n",
    "    left_eye = np.array(l[left_eye[:]][:], dtype = int)\n",
    "\n",
    "    right_eye = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246]\n",
    "    right_eye = np.array(l[right_eye[:]][:], dtype = int)\n",
    "\n",
    "    # Points required to find EAR\n",
    "    left_points = np.array(l[[386, 374, 263, 362]][:], dtype = int)\n",
    "    right_points = np.array(l[[159, 145, 133, 33]][:], dtype = int)\n",
    "\n",
    "    # Calculating Eye aspect ratio for left and right eye and average EAR\n",
    "    leftEAR = EAR(left_points)\n",
    "    rightEAR = EAR(right_points)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "    # Drawing contours over eyes\n",
    "    leftHull =  cv.convexHull(left_eye)\n",
    "    rightHull =  cv.convexHull(right_eye)\n",
    "    cv.drawContours(frame, [leftHull], -1, (0, 255, 0), 1)\n",
    "    cv.drawContours(frame, [rightHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "    # If EAR is more than threshold value then eyes are considered closed\n",
    "    if (ear > 5):\n",
    "        counter_eye += 1\n",
    "\n",
    "        # If eyes are closed for 60 frames or more\n",
    "        if(counter_eye >= 60):    \n",
    "            d[0] = 1\n",
    "    else: \n",
    "        d[0] = 0\n",
    "        counter_eye = 0\n",
    "    \n",
    "    # Drawing contour over lips\n",
    "    lip_land = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, \n",
    "        88, 95,185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] \n",
    "    \n",
    "    lip = np.array(l[lip_land[:]][:], dtype = int)\n",
    "    lipHull = cv.convexHull(lip)\n",
    "    cv.drawContours(frame, [lipHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "    # Indexes for top,bottom and left, right of lips\n",
    "    left_right = np.array(l[[78, 308]][:], dtype = int)\n",
    "    top_bot = np.array(l[[13, 14]][:], dtype = int)\n",
    "    \n",
    "    # Calculating lip ratio\n",
    "    lip_ratio = LAR(top_bot, left_right)\n",
    "    \n",
    "    if(lip_ratio < 1.8):\n",
    "        counter_lip += 1\n",
    "        if(counter_lip >= 45):\n",
    "            d[1] = 1\n",
    "    else:\n",
    "        counter_lip = 0\n",
    "        d[1] = 0\n",
    "        \n",
    "    if (d[0] == 1) or (d[0] == 1 and d[1] == 1):\n",
    "        # Making a thread object and starting it to play the sound if not already playing\n",
    "        if(alarm == 0): \n",
    "            alarm = 1\n",
    "\n",
    "            # Replace beep.wav with whatever sound you have saved\n",
    "            t = Thread(target = sound, args = ('beep.wav',)) \n",
    "            s = 1\n",
    "            t.start()\n",
    "\n",
    "        cv.putText(frame, 'DROWSINESS ALERT!', (10, 30),\n",
    "        cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    else:\n",
    "        # End the sound thread if eyes are no longer closed and person is not yawning\n",
    "        if(alarm == 1):\n",
    "            s = 0\n",
    "            t.join()\n",
    "        alarm = 0\n",
    "\n",
    "    cv.imshow('Video', frame)\n",
    "    key = cv.waitKey(1)\n",
    "    if key == 27:\n",
    "      \tbreak          \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *In short,* \n",
    "- *we'll continuously reads frames from a video stream*\n",
    "- *analyzes facial landmarks for eye and lip-related features and* \n",
    "- *detects drowsiness and yawning based on specific thresholds and conditions* \n",
    "\n",
    "##### *As an output, we'll receive the visual feedback through* **contour drawings** *and displays a warning message on the frame when* **drowsiness** *or* **yawning** *is detected.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
